*** Project: AI-Powered Resume Screening System ***

ðŸ“Œ Goal of the Project:

To develop an AI-driven resume screening system that efficiently ranks multiple resumes based on their similarity to a given job description, using Natural Language Processing (NLP) and Machine Learning techniques.
---

## **ðŸ“Œ Table of Contents**
1ï¸âƒ£ Introduction  
2ï¸âƒ£ Libraries Used and Their Role  
3ï¸âƒ£ Code Breakdown with Explanation  
4ï¸âƒ£ TF-IDF + Cosine Similarity: Why & How?  
5ï¸âƒ£ Ranking System (High, Medium, Low)  
6ï¸âƒ£ Selecting Top N Resumes  
7ï¸âƒ£ Running the Streamlit App  
8ï¸âƒ£ Possible Improvements  

---

## **1ï¸âƒ£ Introduction**
This **Streamlit-powered Resume Screening App** allows users to **upload multiple resumes** and **compare them with a given job description**. It ranks resumes based on **text similarity** using **TF-IDF & Cosine Similarity**. The **top matching resumes** are then displayed in a ranked order.

### **ðŸ”¹ Key Features:**
âœ… Supports **PDF & DOCX** formats  
âœ… Uses **Natural Language Processing (NLP)** to extract keywords  
âœ… Computes **TF-IDF + Cosine Similarity** to measure similarity  
âœ… Categorizes resumes into **High, Medium, Low** ranks  
âœ… Lets users **select top N resumes**  

---

## **2ï¸âƒ£ Libraries Used & Their Role**
### **ðŸ”¹ 1. `streamlit`**  
Used for creating the **interactive web app**, handling **file uploads**, and displaying results.

### **ðŸ”¹ 2. `pdfminer.six`**  
Extracts **text from PDF files**.

### **ðŸ”¹ 3. `python-docx`**  
Extracts **text from Word (DOCX) files**.

### **ðŸ”¹ 4. `spacy`**  
Processes **natural language text**, removing **stopwords** (common words like *"the", "and"*) and extracting **keywords**.

### **ðŸ”¹ 5. `sklearn.feature_extraction.text.TfidfVectorizer`**  
Converts **text data into numerical vectors** using **TF-IDF** (Term Frequency-Inverse Document Frequency), which represents how important words are in a document.

### **ðŸ”¹ 6. `sklearn.metrics.pairwise.cosine_similarity`**  
Calculates **similarity between the job description and resumes** based on **TF-IDF vectors**.

---

## **3ï¸âƒ£ Code Breakdown with Explanation**
Let's break down the **main parts of the code**:

### **ðŸ”¹ Step 1: Load NLP Model**
```python
try:
    nlp = spacy.load("en_core_web_sm")
except OSError:
    st.error("Spacy model 'en_core_web_sm' not found. Run `python -m spacy download en_core_web_sm` to install it.")
    st.stop()
```
ðŸ”¹ Loads the **Spacy NLP model** to process text.  
ðŸ”¹ If the model is missing, it shows an **error message** and stops execution.

---

### **ðŸ”¹ Step 2: Streamlit UI**
```python
st.title("ðŸ“„ Multi-Resume Screening App")
st.write("Upload multiple resumes (PDF/DOCX) and enter a job description to rank them based on relevance.")
```
ðŸ”¹ **Displays the app title & description**.

```python
job_description = st.text_area("ðŸ“Œ Enter Job Description:")
uploaded_files = st.file_uploader("ðŸ“‚ Upload Resumes (Max 10)", type=["pdf", "docx"], accept_multiple_files=True)
top_n = st.number_input("ðŸŽ¯ Select Top N Resumes to Display", min_value=1, max_value=10, value=3, step=1)
```
ðŸ”¹ **User inputs:**  
- A **job description**  
- Uploads **multiple resumes** (Max **10**)  
- Selects **Top N Resumes** to display  

---

### **ðŸ”¹ Step 3: Process Each Resume**
```python
resume_scores = []

for file in uploaded_files:
    if file.name.endswith(".pdf"):
        resume_text = extract_text_from_pdf(file).lower()
    else:
        doc = Document(file)
        resume_text = "\n".join([para.text for para in doc.paragraphs]).lower()
```
ðŸ”¹ **Extracts text** from PDF & DOCX resumes.  
ðŸ”¹ **Converts text to lowercase** for consistency.

---

### **ðŸ”¹ Step 4: NLP - Extract Keywords**
```python
resume_keywords = {token.text for token in nlp(resume_text) if token.is_alpha and not token.is_stop}
job_desc_keywords = {token.text for token in nlp(job_description) if token.is_alpha and not token.is_stop}
```
ðŸ”¹ **Tokenizes** the text into words.  
ðŸ”¹ **Removes stopwords & punctuation** (e.g., "is", "the").  
ðŸ”¹ Extracts **only meaningful keywords**.

---

### **ðŸ”¹ Step 5: Compute TF-IDF + Cosine Similarity**
```python
vectorizer = TfidfVectorizer()
tfidf_matrix = vectorizer.fit_transform([" ".join(job_desc_keywords), " ".join(resume_keywords)])
score = round(cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])[0][0] * 100, 2)
resume_scores.append((file.name, score))
```
ðŸ”¹ **Converts keywords into numerical vectors**.  
ðŸ”¹ **Calculates similarity** using **Cosine Similarity**.  
ðŸ”¹ **Stores the resume & its similarity score**.

---

## **4ï¸âƒ£ TF-IDF + Cosine Similarity: Why & How?**
ðŸ”¹ **TF-IDF (Term Frequency-Inverse Document Frequency)**  
- Measures how important a word is in a document.  
- Gives higher weight to **unique words** and **lowers common words**.  

ðŸ”¹ **Cosine Similarity**  
- Computes **how similar two documents are**.  
- **1 = 100% similarity**, **0 = No similarity**.  

---

## **5ï¸âƒ£ Ranking System (High, Medium, Low)**
```python
high_matches = [res for res in resume_scores if res[1] >= 70]
medium_matches = [res for res in resume_scores if 40 <= res[1] < 70]
low_matches = [res for res in resume_scores if res[1] < 40]
```
ðŸ”¹ **High Match:** â‰¥ **70%**  
ðŸ”¹ **Medium Match:** **40-69%**  
ðŸ”¹ **Low Match:** < **40%**  

```python
st.success("âœ… High Match Resumes (â‰¥ 70%)")
st.warning("âš ï¸ Medium Match Resumes (40% - 69%)")
st.error("âŒ Low Match Resumes (< 40%)")
```
ðŸ”¹ **Displays ranked resumes in color-coded categories**.  

---

## **6ï¸âƒ£ Selecting Top N Resumes**
```python
st.subheader(f"ðŸ† Top {top_n} Resume(s) Based on Match Score")
for i in range(min(top_n, len(resume_scores))):
    st.write(f"ðŸ¥‡ {resume_scores[i][0]} â†’ Match Score: {resume_scores[i][1]}%")
```
ðŸ”¹ Sorts **resumes in descending order**.  
ðŸ”¹ **Displays only the Top N resumes**.  

---

## **7ï¸âƒ£ Running the Streamlit App**
**To run the app:**  
1ï¸âƒ£ **Install dependencies:**  
```bash
pip install streamlit spacy pdfminer.six python-docx scikit-learn
python -m spacy download en_core_web_sm
```
2ï¸âƒ£ **Run the app:**  
```bash
streamlit run app.py
```

---

## **8ï¸âƒ£ Possible Improvements**
âœ… **Use Large Language Models (LLMs) for better matching**  
âœ… **Improve ranking with more NLP techniques**  
âœ… **Add experience & skill-based filtering**  

---

### **ðŸš€ Conclusion**
This **Resume Screening App** effectively filters resumes **based on job descriptions**, using **TF-IDF & Cosine Similarity**. It helps recruiters quickly find the **best-fit resumes** in a **ranked order**.  

Now, youâ€™re ready to **build and improve** your resume screening system! ðŸš€ Let me know if you have any questions. ðŸ˜Š
